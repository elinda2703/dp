{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LineString', 'Moran', 'Polygon', 'Voronoi', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'box', 'build_g_borders', 'build_g_region', 'build_g_rook', 'coo_array', 'create_corrupted_graphs', 'csr_matrix', 'diags', 'extract_subset', 'generate_hex_lattice', 'generate_pent_lattice', 'generate_square_lattice', 'gpd', 'graph', 'identity', 'math', 'np', 'pd', 'plot_graph', 'plot_lattice', 'plt', 'polygonize', 'reindex', 'remove_random_edges', 'simulate_autocorrelated_data', 'sns', 'spmatrix', 'spsolve', 'triu', 'unary_union']\n"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "print(dir(tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import identity, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import geopandas as gpd\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#from libpysal.weights import Queen, Rook\n",
    "import matplotlib.pyplot as plt\n",
    "from esda.moran import Moran\n",
    "#from shapely.geometry import Polygon\n",
    "#import copy\n",
    "import seaborn as sns\n",
    "from libpysal import graph,weights\n",
    "#from splot.libpysal import plot_spatial_weights\n",
    "#from scipy.sparse import spmatrix, triu, diags, coo_array\n",
    "from tools import generate_square_lattice,remove_random_edges,simulate_autocorrelated_data\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "#from spreg import ML_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = ['square','pent','hex']\n",
    "sizes = [25,100,400]\n",
    "corruption_methods = ['random','border','periphery','center']\n",
    "n_runs = 10\n",
    "c_runs = 10\n",
    "rhos = np.arange(-0.9, 1.0, 0.1)\n",
    "perc_missing = np.linspace(5,95, 19)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\elapo\\AppData\\Local\\Temp\\ipykernel_42472\\1158676420.py:22: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  gdf = gpd.read_parquet(f'data\\gdf_{shape}_{size}.parquet')\n",
      "Calculating Moran's I:   0%|          | 8/1299600 [00:00<25:16:43, 14.28it/s]\n",
      "C:\\Users\\elapo\\AppData\\Local\\Temp\\ipykernel_42472\\1158676420.py:22: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  gdf = gpd.read_parquet(f'data\\gdf_{shape}_{size}.parquet')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "graphs/square/size_25/random/g_45_0.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m shape, size, method, n_run, c_run, rho, p \u001b[38;5;129;01min\u001b[39;00m tqdm(combinations, total=total_iters, desc=\u001b[33m\"\u001b[39m\u001b[33mCalculating Moran\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms I\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     22\u001b[39m     gdf = gpd.read_parquet(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mgdf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     wm = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgraphs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/size_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmethod\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/g_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mc_run\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.to_W()\n\u001b[32m     24\u001b[39m     col_prefix = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrho_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrho\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m     y = gdf[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_run_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m].values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\libpysal\\graph\\base.py:2742\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, **kwargs)\u001b[39m\n\u001b[32m   2719\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(path, **kwargs):\n\u001b[32m   2720\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read Graph from a Apache Parquet\u001b[39;00m\n\u001b[32m   2721\u001b[39m \n\u001b[32m   2722\u001b[39m \u001b[33;03m    Read Graph serialized using `Graph.to_parquet()` back into the `Graph` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2740\u001b[39m \u001b[33;03m    >>> graph.read_parquet(\"contiguity.parquet\")\u001b[39;00m\n\u001b[32m   2741\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2742\u001b[39m     adjacency, transformation, xarray_index_names = \u001b[43m_read_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2743\u001b[39m     graph_obj = Graph(adjacency, transformation, is_sorted=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2744\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xarray_index_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\libpysal\\graph\\io\\_parquet.py:59\u001b[39m, in \u001b[36m_read_parquet\u001b[39m\u001b[34m(source, **kwargs)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpyarrow is required for `read_parquet`.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m table = \u001b[43mpq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlibpysal\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m table.schema.metadata:\n\u001b[32m     61\u001b[39m     meta = json.loads(table.schema.metadata[\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlibpysal\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1844\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[39m\n\u001b[32m   1832\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_table\u001b[39m(source, *, columns=\u001b[38;5;28;01mNone\u001b[39;00m, use_threads=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1833\u001b[39m                schema=\u001b[38;5;28;01mNone\u001b[39;00m, use_pandas_metadata=\u001b[38;5;28;01mFalse\u001b[39;00m, read_dictionary=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1834\u001b[39m                binary_type=\u001b[38;5;28;01mNone\u001b[39;00m, list_type=\u001b[38;5;28;01mNone\u001b[39;00m, memory_map=\u001b[38;5;28;01mFalse\u001b[39;00m, buffer_size=\u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1840\u001b[39m                page_checksum_verification=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1841\u001b[39m                arrow_extensions_enabled=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1843\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1844\u001b[39m         dataset = \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1850\u001b[39m \u001b[43m            \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1851\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbinary_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1852\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlist_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlist_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1853\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1854\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1855\u001b[39m \u001b[43m            \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1856\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m            \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1862\u001b[39m \u001b[43m            \u001b[49m\u001b[43marrow_extensions_enabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrow_extensions_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1864\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1865\u001b[39m         \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[32m   1866\u001b[39m         \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[32m   1867\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1424\u001b[39m, in \u001b[36mParquetDataset.__init__\u001b[39m\u001b[34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[39m\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m partitioning == \u001b[33m\"\u001b[39m\u001b[33mhive\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1421\u001b[39m     partitioning = ds.HivePartitioning.discover(\n\u001b[32m   1422\u001b[39m         infer_dictionary=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1424\u001b[39m \u001b[38;5;28mself\u001b[39m._dataset = \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mparquet_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\pyarrow\\dataset.py:790\u001b[39m, in \u001b[36mdataset\u001b[39m\u001b[34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[39m\n\u001b[32m    779\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    780\u001b[39m     schema=schema,\n\u001b[32m    781\u001b[39m     filesystem=filesystem,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     selector_ignore_prefixes=ignore_prefixes\n\u001b[32m    787\u001b[39m )\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\pyarrow\\dataset.py:472\u001b[39m, in \u001b[36m_filesystem_dataset\u001b[39m\u001b[34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[39m\n\u001b[32m    470\u001b[39m         fs, paths_or_selector = _ensure_multiple_sources(source, filesystem)\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     fs, paths_or_selector = \u001b[43m_ensure_single_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m options = FileSystemFactoryOptions(\n\u001b[32m    475\u001b[39m     partitioning=partitioning,\n\u001b[32m    476\u001b[39m     partition_base_dir=partition_base_dir,\n\u001b[32m    477\u001b[39m     exclude_invalid_files=exclude_invalid_files,\n\u001b[32m    478\u001b[39m     selector_ignore_prefixes=selector_ignore_prefixes\n\u001b[32m    479\u001b[39m )\n\u001b[32m    480\u001b[39m factory = FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elapo\\OneDrive\\Dokumenty\\prf\\dp\\code\\.pixi\\envs\\default\\Lib\\site-packages\\pyarrow\\dataset.py:437\u001b[39m, in \u001b[36m_ensure_single_source\u001b[39m\u001b[34m(path, filesystem)\u001b[39m\n\u001b[32m    435\u001b[39m     paths_or_selector = [path]\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filesystem, paths_or_selector\n",
      "\u001b[31mFileNotFoundError\u001b[39m: graphs/square/size_25/random/g_45_0.parquet"
     ]
    }
   ],
   "source": [
    "# 2. Calculate the total number of iterations (strictly for the progress bar to work)\n",
    "total_iters = len(shapes) * len(sizes) * len(corruption_methods) * n_runs * c_runs * len(rhos) * len(perc_missing)\n",
    "\n",
    "# 3. Create the combinations generator\n",
    "# Note: Because n_runs and c_runs are integers, we wrap them in range()\n",
    "combinations = itertools.product(\n",
    "    shapes, \n",
    "    sizes, \n",
    "    corruption_methods, \n",
    "    range(n_runs), \n",
    "    range(c_runs), \n",
    "    rhos, \n",
    "    perc_missing\n",
    ")\n",
    "\n",
    "# 1. The Golden Rule: Create an empty list OUTSIDE the loop\n",
    "all_results = []\n",
    "\n",
    "for shape, size, method, n_run, c_run, rho, p in tqdm(combinations, total=total_iters, desc=\"Calculating Moran's I\"):\n",
    "    \n",
    "    \n",
    "    gdf = gpd.read_parquet(f'data\\gdf_{shape}_{size}.parquet')\n",
    "    wm = graph.read_parquet(f\"graphs/{shape}/size_{size}/{method}/g_{int(p)}_{c_run}.parquet\").to_W()\n",
    "    col_prefix = f\"rho_{rho:.1f}\"\n",
    "    y = gdf[f\"{col_prefix}_run_{n_run}\"].values\n",
    "    mi_cor = Moran(y, wm)\n",
    "    \n",
    "    \n",
    "    # 2. Build your dictionary using the exact loop variables\n",
    "    iteration_result = {\n",
    "        \"shape\": shape,\n",
    "        \"size\": size,\n",
    "        \"corruption_method\": method,\n",
    "        \"rho\": rho,\n",
    "        \"p_missing\": p,                \n",
    "        \"corruption_run\": c_run,\n",
    "        \"data_run\": n_run,\n",
    "        \"moran_i\": mi_cor.I,\n",
    "        \"p_value\": mi_cor.p_sim\n",
    "    }\n",
    "    \n",
    "    # 3. Append the dictionary to your list (Python does this in nanoseconds)\n",
    "    all_results.append(iteration_result)\n",
    "\n",
    "# 4. OUTSIDE THE LOOP: Convert the 1.3 million dictionaries into a DataFrame instantly!\n",
    "final_df = pd.DataFrame(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
